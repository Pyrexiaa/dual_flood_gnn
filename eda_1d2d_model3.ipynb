{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2293a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "from data.flood_event_1d2d_dataset import FloodEvent1D2DDataset\n",
    "from utils import file_utils, plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf49df3",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'configs/config_1d2d_model3.yaml'\n",
    "config = file_utils.read_yaml_file(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train' # 'train' or 'test'\n",
    "\n",
    "dataset_parameters = config['dataset_parameters']\n",
    "if mode == 'train':\n",
    "    dataset_summary_file = dataset_parameters['training']['dataset_summary_file']\n",
    "    event_stats_file = dataset_parameters['training']['event_stats_file']\n",
    "else: # mode == 'test'\n",
    "    dataset_summary_file = dataset_parameters['testing']['dataset_summary_file']\n",
    "    event_stats_file = dataset_parameters['testing']['event_stats_file']\n",
    "\n",
    "delta_t = dataset_parameters['timestep_interval']\n",
    "previous_timesteps = dataset_parameters['previous_timesteps']\n",
    "dataset = FloodEvent1D2DDataset(\n",
    "    mode=mode,\n",
    "    root_dir=dataset_parameters['root_dir'],\n",
    "    dataset_summary_file=dataset_summary_file,\n",
    "    nodes_2d_shp_file=dataset_parameters['nodes_2d_shp_file'],\n",
    "    edges_2d_shp_file=dataset_parameters['edges_2d_shp_file'],\n",
    "    nodes_1d_shp_file=dataset_parameters['nodes_1d_shp_file'],\n",
    "    edges_1d_shp_file=dataset_parameters['edges_1d_shp_file'],\n",
    "    edges_1d2d_shp_file=dataset_parameters['edges_1d2d_shp_file'],\n",
    "    dem_file=dataset_parameters['dem_file'],\n",
    "    event_stats_file=event_stats_file,\n",
    "    features_stats_file=dataset_parameters['features_stats_file'],\n",
    "    previous_timesteps=dataset_parameters['previous_timesteps'],\n",
    "    normalize=dataset_parameters['normalize'],\n",
    "    timestep_interval=delta_t,\n",
    "    spin_up_time=dataset_parameters['spin_up_time'],\n",
    "    time_from_peak=dataset_parameters['time_from_peak'],\n",
    "    inflow_boundary_nodes=dataset_parameters['inflow_boundary_nodes'],\n",
    "    outflow_boundary_nodes=dataset_parameters['outflow_boundary_nodes'],\n",
    "    with_global_mass_loss=False,\n",
    "    with_local_mass_loss=False,\n",
    "    force_reload=True,\n",
    "    save=True,\n",
    "    perimeter_name=dataset_parameters['perimeter_name'],\n",
    "    network_name=dataset_parameters['network_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024202e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of events: {len(dataset.hec_ras_run_ids)}')\n",
    "print(f'Total number of timesteps: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba809b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    start_ts = 0\n",
    "    end_ts = None\n",
    "else:  # mode == 'test'\n",
    "    rollout_start = config['testing_parameters']['rollout_start']\n",
    "    rollout_timesteps = config['testing_parameters']['rollout_timesteps']\n",
    "    start_ts = rollout_start\n",
    "    end_ts = (start_ts + rollout_timesteps) if rollout_timesteps is not None else None\n",
    "\n",
    "delta_t_in_hours = delta_t / 3600\n",
    "num_events = len(dataset.hec_ras_run_ids)\n",
    "tick_interval_in_hours = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_per_event(\n",
    "    dynamic_paths: List[str],\n",
    "    data_key: str,\n",
    "    feature_name: str,\n",
    "    feature_idx: int,\n",
    "    ylabel: str,\n",
    "    title: str,\n",
    "    aggregation_func: Callable = None,\n",
    "    mask: np.ndarray = None,\n",
    "):\n",
    "    longest_hours_elapsed = []\n",
    "    for run_id, path in zip(dataset.hec_ras_run_ids, dynamic_paths):\n",
    "        data = np.load(path)[data_key][previous_timesteps:]\n",
    "        feature_data = data[start_ts:end_ts, :, feature_idx]\n",
    "\n",
    "        if mask is not None:\n",
    "            # print(f'Applying mask: {mask}')\n",
    "            feature_data = feature_data[:, mask]\n",
    "\n",
    "        feature_data = dataset.normalizer.denormalize(feature_name, feature_data)\n",
    "\n",
    "        if aggregation_func is not None:\n",
    "            feature_data = aggregation_func(feature_data)\n",
    "\n",
    "        # Plot\n",
    "        hours_elapsed = np.arange(len(feature_data)) * delta_t_in_hours\n",
    "        plt.plot(hours_elapsed, feature_data, label=f'Run {run_id}')\n",
    "\n",
    "        if len(hours_elapsed) > len(longest_hours_elapsed):\n",
    "            longest_hours_elapsed = hours_elapsed\n",
    "\n",
    "    # Configure plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (h)')\n",
    "    interval_ticks = np.arange(0, len(longest_hours_elapsed), int(tick_interval_in_hours / delta_t_in_hours))\n",
    "    plt.xticks(longest_hours_elapsed[interval_ticks])\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bddc3",
   "metadata": {},
   "source": [
    "# Plot 2D Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d233270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_nodes_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "node_data_key = 'dynamic_nodes'\n",
    "water_volume_idx = FloodEvent1D2DDataset.DYNAMIC_NODE_FEATURES.index('water_level')\n",
    "\n",
    "plot_timeseries_per_event(\n",
    "    dynamic_paths=dynamic_nodes_paths,\n",
    "    data_key=node_data_key,\n",
    "    feature_name='water_level',\n",
    "    feature_idx=water_volume_idx,\n",
    "    ylabel='Water Level (m)',\n",
    "    title='Total Water Level per Timestep',\n",
    "    aggregation_func=lambda x: x.sum(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95209fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_idx = FloodEvent1D2DDataset.DYNAMIC_NODE_FEATURES.index('rainfall')\n",
    "\n",
    "plot_timeseries_per_event(\n",
    "    dynamic_paths=dynamic_nodes_paths,\n",
    "    data_key=node_data_key,\n",
    "    feature_name='rainfall',\n",
    "    feature_idx=rainfall_idx,\n",
    "    ylabel='Rainfall Volume (m³)',\n",
    "    title='Total Rainfall Volume per Timestep',\n",
    "    aggregation_func=lambda x: x.sum(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3d7bc",
   "metadata": {},
   "source": [
    "# Plot 1D Dynamic Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045dea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_nodes_1d_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "node_1d_data_key = 'dynamic_nodes_1d'\n",
    "water_level_idx = FloodEvent1D2DDataset.DYNAMIC_1D_NODE_FEATURES.index('water_level')\n",
    "\n",
    "plot_timeseries_per_event(\n",
    "    dynamic_paths=dynamic_nodes_1d_paths,\n",
    "    data_key=node_1d_data_key,\n",
    "    feature_name='water_level',\n",
    "    feature_idx=water_level_idx,\n",
    "    ylabel='Water Level (m)',\n",
    "    title='Average Water Level per Timestep (1D)',\n",
    "    aggregation_func=lambda x: x.mean(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570db75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_nodes_1d_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "node_1d_data_key = 'dynamic_nodes_1d'\n",
    "water_level_idx = FloodEvent1D2DDataset.DYNAMIC_1D_NODE_FEATURES.index('inlet_flow')\n",
    "\n",
    "plot_timeseries_per_event(\n",
    "    dynamic_paths=dynamic_nodes_1d_paths,\n",
    "    data_key=node_1d_data_key,\n",
    "    feature_name='inlet_flow',\n",
    "    feature_idx=water_level_idx,\n",
    "    ylabel='Inlet Flow (m)',\n",
    "    title='Average Inlet Flow per Timestep (1D)',\n",
    "    aggregation_func=lambda x: x.mean(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf90da",
   "metadata": {},
   "source": [
    "# Plot 2D Dynamic Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c831f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total inflow per timestep\n",
    "dynamic_edges_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "edge_data_key = 'dynamic_edges'\n",
    "flow_idx = FloodEvent1D2DDataset.DYNAMIC_EDGE_FEATURES.index('face_flow')\n",
    "inflow_edge_mask = dataset.boundary_condition.inflow_edges_mask\n",
    "\n",
    "plot_timeseries_per_event(\n",
    "    dynamic_paths=dynamic_edges_paths,\n",
    "    data_key=edge_data_key,\n",
    "    feature_name='face_flow',\n",
    "    feature_idx=flow_idx,\n",
    "    ylabel='Inflow (m³/s)',\n",
    "    title='Boundary Inflow per Timestep',\n",
    "    mask=inflow_edge_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_end_idx = [*dataset.event_start_idx, dataset.total_rollout_timesteps]\n",
    "event_size = np.diff(event_end_idx)\n",
    "\n",
    "for i, run_id in enumerate(dataset.hec_ras_run_ids):\n",
    "    print(f'Run {run_id} - Event Size: {event_size[i]} timesteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d66f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_diff_entities(dynamic_path: str,\n",
    "                              data_key: str,\n",
    "                              feature_name: str,\n",
    "                              feature_idx: int,\n",
    "                              k: int = 4) -> Tuple[List, np.ndarray]:\n",
    "    data = np.load(dynamic_path)[data_key]\n",
    "    feature_data = data[:, :, feature_idx]\n",
    "    feature_data = dataset.normalizer.denormalize(feature_name, feature_data)\n",
    "    feature_diff = np.abs(np.diff(feature_data, axis=0))\n",
    "    feature_diff_per_entity = feature_diff.sum(axis=0)\n",
    "\n",
    "    top_k_diff_idx = np.argsort(feature_diff_per_entity)[-k:][::-1].tolist()\n",
    "    top_k_wd_diff = feature_diff_per_entity[top_k_diff_idx]\n",
    "    return top_k_diff_idx, top_k_wd_diff\n",
    "\n",
    "\n",
    "EVENT_IDX = 0  # Change this to the desired event index\n",
    "k = 5  # Number of top nodes to retrieve\n",
    "\n",
    "event_dynamic_nodes_path = dynamic_nodes_paths[EVENT_IDX]\n",
    "top_k_wv_diff_idx, top_k_wv_diff = get_highest_diff_entities(dynamic_path=event_dynamic_nodes_path,\n",
    "                                                             data_key=node_data_key,\n",
    "                                                             feature_name='water_volume',\n",
    "                                                             feature_idx=water_volume_idx,\n",
    "                                                             k=k)\n",
    "print('Nodes with the highest water volume difference:')\n",
    "for idx, wv in zip(top_k_wv_diff_idx, top_k_wv_diff):\n",
    "    print(f\"Node {idx}: {wv:.2f} m\")\n",
    "\n",
    "run_id = dataset.hec_ras_run_ids[EVENT_IDX]\n",
    "node_df = plot_utils.get_node_df(config, run_id, mode=mode, no_ghost=True)\n",
    "plot_utils.plot_cell_map_w_highlight(gpdf=node_df,\n",
    "                                     title=f'Top {k} Nodes with Highest Water Volume Difference for event {run_id}',\n",
    "                                     highlight_idxs=top_k_wv_diff_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdad364",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_node_idx = [534, 644, 767, 463]\n",
    "color_list = ['#4169E1', '#FF0000', '#3CB371', '#8F00FF']\n",
    "plot_utils.plot_cell_map_w_highlight(node_df,\n",
    "                                    title='Selected Nodes',\n",
    "                                    highlight_idxs=highlight_node_idx,\n",
    "                                    color_list=color_list,\n",
    "                                    legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51513e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_diff_water_flow_edges(dataset: FloodEvent1D2DDataset, event_idx: int, k: int = 4) -> tuple[list, np.ndarray]:\n",
    "    num_events = len(dataset.hec_ras_run_ids)\n",
    "    dynamic_edges_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "\n",
    "    dynamic_edges = np.load(dynamic_edges_paths[event_idx])['dynamic_edges']\n",
    "    water_flow_idx = FloodEvent1D2DDataset.DYNAMIC_EDGE_FEATURES.index(FloodEvent1D2DDataset.EDGE_TARGET_FEATURE)\n",
    "    water_flow = dynamic_edges[:, :, water_flow_idx]\n",
    "    water_flow = dataset.normalizer.denormalize(FloodEvent1D2DDataset.EDGE_TARGET_FEATURE, water_flow)\n",
    "    wf_diff = np.abs(np.diff(water_flow, axis=0))\n",
    "    wf_diff_per_edge = wf_diff.sum(axis=0)\n",
    "\n",
    "    top_k_diff_idx = np.argsort(wf_diff_per_edge)[-k:][::-1].tolist()\n",
    "    top_k_wf_diff = wf_diff_per_edge[top_k_diff_idx]\n",
    "    return top_k_diff_idx, top_k_wf_diff\n",
    "\n",
    "# def get_edge_df(dataset: FloodEventDataset, no_ghost: bool = True) -> gpd.GeoDataFrame:\n",
    "#     edges_shp_path = dataset.raw_paths[1]\n",
    "#     link_df = gpd.read_file(edges_shp_path)\n",
    "\n",
    "#     if no_ghost:\n",
    "#         bc = dataset.boundary_condition\n",
    "#         inflow_boundary_nodes = dataset.inflow_boundary_nodes\n",
    "#         outflow_boundary_nodes = dataset.outflow_boundary_nodes\n",
    "#         is_ghost_edge = link_df['from_node'].isin(bc.ghost_nodes) | link_df['to_node'].isin(bc.ghost_nodes)\n",
    "#         boundary_nodes = np.concat([np.array(dataset.inflow_boundary_nodes), np.array(dataset.outflow_boundary_nodes)])\n",
    "#         is_boundary_edge = link_df['from_node'].isin(boundary_nodes) | link_df['to_node'].isin(boundary_nodes)\n",
    "#         link_df = pd.concat([link_df[~is_ghost_edge], link_df[is_ghost_edge & is_boundary_edge]], ignore_index=True)\n",
    "\n",
    "#         assert np.all(link_df['from_node'][bc.inflow_edges_mask].isin(inflow_boundary_nodes) | link_df['to_node'][bc.inflow_edges_mask].isin(inflow_boundary_nodes)), \"Inflow of link DataFrame does not match the inflow edges mask\"\n",
    "#         assert np.all(link_df['from_node'][bc.outflow_edges_mask].isin(outflow_boundary_nodes) | link_df['to_node'][bc.outflow_edges_mask].isin(outflow_boundary_nodes)), \"Outflow of link DataFrame does not match the outflow edges mask\"\n",
    "\n",
    "#     return link_df\n",
    "\n",
    "EVENT_IDX = 0  # Change this to the desired event index\n",
    "k = 5  # Number of top edges to retrieve\n",
    "\n",
    "event_dynamic_edges_path = dynamic_edges_paths[EVENT_IDX]\n",
    "top_k_wf_diff_idx, top_k_wf_diff = get_highest_diff_entities(dynamic_path=event_dynamic_edges_path,\n",
    "                                                             data_key=edge_data_key,\n",
    "                                                             feature_name='face_flow',\n",
    "                                                             feature_idx=flow_idx,\n",
    "                                                             k=k)\n",
    "print('Edges with the highest water flow difference:')\n",
    "for idx, wf in zip(top_k_wf_diff_idx, top_k_wf_diff):\n",
    "    print(f\"Edge {idx}: {wf:.2f} m\")\n",
    "\n",
    "run_id = dataset.hec_ras_run_ids[EVENT_IDX]\n",
    "edge_df = plot_utils.get_edge_df(config, run_id, mode=mode, no_ghost=True)\n",
    "plot_utils.plot_cell_map_w_highlight(gpdf=edge_df,\n",
    "                                     title=f'Top {k} Edges with Highest Water Flow Difference for event {run_id}',\n",
    "                                     highlight_idxs=top_k_wf_diff_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892860e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_edge_idx = [1609, 1101, 1897, 559]\n",
    "color_list = ['#4169E1', '#FF0000', '#3CB371', '#8F00FF']\n",
    "plot_utils.plot_cell_map_w_highlight(edge_df,\n",
    "                                     title='Selected Edges',\n",
    "                                     highlight_idxs=highlight_edge_idx,\n",
    "                                     color_list=color_list,\n",
    "                                     legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b460292",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stats_path = dataset.processed_paths[1]\n",
    "feature_stats = file_utils.read_yaml_file(feature_stats_path)\n",
    "print(\"Feature statistics:\")\n",
    "for feature_name, stats in feature_stats.items():\n",
    "    print(f\"{feature_name}\")\n",
    "    print(f\"\\tMean: {stats['mean']:.4f}\")\n",
    "    print(f\"\\tStd: {stats['std']:.4f}\")\n",
    "    print(f\"\\tMin: {stats['min']:.4f}\")\n",
    "    print(f\"\\tMax: {stats['max']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a163aee",
   "metadata": {},
   "source": [
    "# Plot 2D Static Node & Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_values_path = dataset.processed_paths[3]\n",
    "bins = 50\n",
    "\n",
    "static_features = FloodEvent1D2DDataset.STATIC_NODE_FEATURES + FloodEvent1D2DDataset.STATIC_EDGE_FEATURES\n",
    "feature_idxs = [*(range(dataset.num_static_node_features)), *(range(dataset.num_static_edge_features))]\n",
    "keys = [*(['static_nodes'] * dataset.num_static_node_features), *(['static_edges'] * dataset.num_static_edge_features)]\n",
    "for feature, index, key in zip(static_features, feature_idxs, keys):\n",
    "    data = np.load(constant_values_path)[key]\n",
    "    feature_data = data[:, index]\n",
    "    if dataset.is_normalized:\n",
    "        feature_data = dataset.normalizer.denormalize(feature, feature_data)\n",
    "    plt.hist(feature_data, bins=bins)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761e054",
   "metadata": {},
   "source": [
    "# Plot 2D Dynamic Node & Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f47e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = len(dataset.hec_ras_run_ids)\n",
    "dynamic_values_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "\n",
    "dynamic_features = FloodEvent1D2DDataset.DYNAMIC_NODE_FEATURES + FloodEvent1D2DDataset.DYNAMIC_EDGE_FEATURES\n",
    "feature_idxs = [*(range(dataset.num_dynamic_node_features)), *(range(dataset.num_dynamic_edge_features))]\n",
    "keys = [*(['dynamic_nodes'] * dataset.num_dynamic_node_features), *(['dynamic_edges'] * dataset.num_dynamic_edge_features)]\n",
    "for feature, index, key in zip(dynamic_features, feature_idxs, keys):\n",
    "    all_feature_data = []\n",
    "    for path in dynamic_values_paths:\n",
    "        data = np.load(path)[key]\n",
    "        feature_data = data[:, :, index]\n",
    "        if dataset.is_normalized:\n",
    "            feature_data = dataset.normalizer.denormalize(feature, feature_data)\n",
    "        all_feature_data.append(feature_data.flatten())\n",
    "    all_feature_data = np.concatenate(all_feature_data)\n",
    "    plt.hist(all_feature_data, bins=bins)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbcf9f0",
   "metadata": {},
   "source": [
    "# Plot 1D Static Node & Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_values_path = dataset.processed_paths[3]\n",
    "bins = 50\n",
    "\n",
    "static_features = FloodEvent1D2DDataset.STATIC_1D_NODE_FEATURES + FloodEvent1D2DDataset.STATIC_1D_EDGE_FEATURES\n",
    "feature_idxs = [*(range(dataset.num_static_node_features)), *(range(dataset.num_static_edge_features))]\n",
    "keys = [*(['static_nodes'] * dataset.num_static_node_features), *(['static_edges'] * dataset.num_static_edge_features)]\n",
    "for feature, index, key in zip(static_features, feature_idxs, keys):\n",
    "    data = np.load(constant_values_path)[key]\n",
    "    feature_data = data[:, index]\n",
    "    if dataset.is_normalized:\n",
    "        feature_data = dataset.normalizer.denormalize(feature, feature_data)\n",
    "    plt.hist(feature_data, bins=bins)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3385929",
   "metadata": {},
   "source": [
    "# Plot 1D Dynamic Node & Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = len(dataset.hec_ras_run_ids)\n",
    "dynamic_values_paths = dataset.processed_paths[4:(num_events + 4)]\n",
    "\n",
    "dynamic_features = FloodEvent1D2DDataset.DYNAMIC_1D_NODE_FEATURES + FloodEvent1D2DDataset.DYNAMIC_1D_EDGE_FEATURES\n",
    "feature_idxs = [*(range(dataset.num_dynamic_node_features)), *(range(dataset.num_dynamic_edge_features))]\n",
    "keys = [*(['dynamic_nodes'] * dataset.num_dynamic_node_features), *(['dynamic_edges'] * dataset.num_dynamic_edge_features)]\n",
    "for feature, index, key in zip(dynamic_features, feature_idxs, keys):\n",
    "    all_feature_data = []\n",
    "    for path in dynamic_values_paths:\n",
    "        data = np.load(path)[key]\n",
    "        feature_data = data[:, :, index]\n",
    "        if dataset.is_normalized:\n",
    "            feature_data = dataset.normalizer.denormalize(feature, feature_data)\n",
    "        all_feature_data.append(feature_data.flatten())\n",
    "    all_feature_data = np.concatenate(all_feature_data)\n",
    "    plt.hist(all_feature_data, bins=bins)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flood_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
